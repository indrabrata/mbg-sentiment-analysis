name: Data Collection

on:
  workflow_dispatch:
    inputs:
      keyword:
        description: "Search keyword"
        required: false
        default: "makan bergizi gratis"
  schedule:
    - cron: "0 18 * * *"

env:
  SEARCH_KEYWORD: ${{ github.event.inputs.keyword || vars.SEARCH_KEYWORD || 'makan bergizi gratis' }}
  TOTAL_DATA: ${{ vars.TOTAL_DATA || '50' }}

jobs:
  data-collection:
    runs-on: ubuntu-latest

    outputs:
      current_date: ${{ steps.date.outputs.current_date }}

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup pnpm
        uses: pnpm/action-setup@v2
        with:
          version: 8

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: "20"
          cache: "pnpm"
          cache-dependency-path: "scrapper/pnpm-lock.yaml"

      - name: Install dependencies
        working-directory: ./scrapper
        run: pnpm install --no-frozen-lockfile

      - name: Build scrapper
        working-directory: ./scrapper
        run: pnpm build

      - name: Get yesterday's date in Indonesia timezone
        id: date
        run: |
          YESTERDAY_DATE=$(TZ='Asia/Jakarta' date -d 'yesterday' +%Y-%m-%d)
          echo "current_date=$YESTERDAY_DATE" >> $GITHUB_OUTPUT

      - name: Run scrapper
        working-directory: ./scrapper
        run: |
          node dist/bin.js \
            -o "mbg" \
            -s "${{ env.SEARCH_KEYWORD }} since:${{ steps.date.outputs.current_date }} lang:id" \
            --tab "LATEST" \
            -l ${{ env.TOTAL_DATA }} \
            --token ${{ secrets.TWITTER_TOKEN }}

      - name: Upload scraped RAW data
        uses: actions/upload-artifact@v4
        with:
          name: raw-${{ steps.date.outputs.current_date }}
          path: scrapper/tweets-data/mbg.csv

  data-preprocessing:
    needs: data-collection
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Download RAW data
        uses: actions/download-artifact@v4
        with:
          name: raw-${{ needs.data-collection.outputs.current_date }}
          path: scrapper/tweets-data

      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: "3.11"

      - name: Install uv
        uses: astral-sh/setup-uv@v5
        with:
          version: "latest"

      - name: Install Python dependencies
        working-directory: ./model
        run: |
          uv pip install --system -e .

      - name: Preprocess tweet data (cleaned)
        working-directory: ./model
        run: |
          python scripts/preprocess_data.py \
            --input ../scrapper/tweets-data/mbg.csv \
            --output_dir ../scrapper/tweets-data

      - name: Add empty label column (unlabeled dataset)
        working-directory: ./model
        run: |
          python scripts/add_label_column.py \
            --input ../scrapper/tweets-data/mbg_cleaned.csv \
            --output_dir ../scrapper/tweets-data \
            --date "${{ needs.data-collection.outputs.current_date }}"

      - name: Upload Cleaned Unlabeled data
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: unlabeled-${{ needs.data-collection.outputs.current_date }}
          path: scrapper/tweets-data/mbg_cleaned_unlabeled_${{ needs.data-collection.outputs.current_date }}.csv
