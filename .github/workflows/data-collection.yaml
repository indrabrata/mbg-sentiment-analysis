name: Data Collection

on:
  workflow_dispatch:
    inputs:
      keyword:
        description: "Search keyword"
        required: false
        default: "makan bergizi gratis"
  schedule:
    # Run daily at 18:00 UTC (01:00 WIB)
    - cron: "0 18 * * *"

env:
  SEARCH_KEYWORD: ${{ github.event.inputs.keyword || vars.SEARCH_KEYWORD || 'makan bergizi gratis' }}
  TOTAL_DATA: ${{ vars.TOTAL_DATA || '50' }}

jobs:
  data-collection:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup pnpm
        uses: pnpm/action-setup@v2
        with:
          version: 8

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: "20"
          cache: "pnpm"
          cache-dependency-path: "scrapper/pnpm-lock.yaml"

      - name: Install dependencies
        working-directory: ./scrapper
        run: pnpm install --no-frozen-lockfile

      - name: Build scrapper
        working-directory: ./scrapper
        run: pnpm build

      - name: Get yesterday's date in Indonesia timezone
        id: date
        run: |
          YESTERDAY_DATE=$(TZ='Asia/Jakarta' date -d 'yesterday' +%Y-%m-%d)
          echo "current_date=$YESTERDAY_DATE" >> $GITHUB_OUTPUT

      - name: Run scrapper
        working-directory: ./scrapper
        run: |
          node dist/bin.js \
            -o "mbg" \
            -s "${{ env.SEARCH_KEYWORD }} since:${{ steps.date.outputs.current_date }} lang:id" \
            --tab "LATEST" \
            -l ${{ env.TOTAL_DATA }} \
            --token ${{ secrets.TWITTER_TOKEN }}

      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: "3.10"

      - name: Install Python dependencies
        run: |
          pip install pandas emoji

      - name: Preprocess tweet data (cleaned)
        run: |
          python model/src/cleaning/cleaned_text.py \
            --input scrapper/tweets-data/mbg.csv \
            --output_dir scrapper/tweets-data \
            --date "${{ steps.date.outputs.current_date }}"

      - name: Add empty label column (unlabeled dataset)
        run: |
          python model/src/cleaning/add_unlabeled_column.py \
            --input scrapper/tweets-data/mbg_cleaned_${{ steps.date.outputs.current_date }}.csv \
            --output_dir scrapper/tweets-data \
            --date "${{ steps.date.outputs.current_date }}"

      - name: Upload RAW scraped data
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: raw-${{ steps.date.outputs.current_date }}
          path: scrapper/tweets-data/mbg.csv
          retention-days: 30

      - name: Upload CLEANED data
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: cleaned-${{ steps.date.outputs.current_date }}
          path: scrapper/tweets-data/mbg_cleaned_${{ steps.date.outputs.current_date }}.csv
          retention-days: 30

      - name: Upload CLEANED UNLABELED data
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: unlabeled-${{ steps.date.outputs.current_date }}
          path: scrapper/tweets-data/mbg_cleaned_unlabeled_${{ steps.date.outputs.current_date }}.csv
          retention-days: 30